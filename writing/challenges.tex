
\section{Why is it hard to evaluate the value of blame?}
\label{sec:challenges}

The most serious challenge for evaluating blame concerns 
the nature of this research. Unlike ordinary
work on programming languages, the question seems to call for empirical research
similar to the one in the human-computer interaction area. At the same time, a
significant evaluation result demands a large number of cases yielding a serious
amount of data. But, as~\citet{lksfd-popl-2020} already demonstrated, the way
around this dilemma is to postulate the equivalent of a {\it homo economicus\/}
for programming languages---the {\em rational programmer\/}---and to implement
this rational programmer as an algorithm.  As indicated in the introduction, in
the context of gradual typing, the rational programmer translates the
Wadler-Findler slogan into a debugging method, searching for the source of the
impedance mismatch in an incremental fashion. Measuring this simulated
programmer's behavior on a large number of inputs then yields relevant 
data, similar to collecting empirical data in a human-focused discipline. 

A derivative challenge is the problem of simulating the programmer's
mistakes or, more precisely, the origin of impedance mismatches. Before a
programmer can try to find mistakes, mistakes have to be made.
Specifically, a necessary step to test the rational programmer is to find
a collection of  type mistakes in  mix-typed programs that is highly
representantive of both mistakes and programs ``in the wild.''
Unfortunately no such collection exists.  There is a good reason for that;
the kind of mistakes the rational programmer targets are easily detected
by unit tests and, even if their sources are hard to find, these mistakes do not make it
into code repositories with appropriate commit messages.  In other words, the problem is how to generate a
sufficiently large and representantive corpus of type mistakes for a meaningful
experiment.  Following~\citet{lksfd-popl-2020} again, the solution is to
use mutation analysis~\cite{lipton1971fault, demillo1978hints,
jia2011analysis} to create mistakes in a synthetic manner. This process
yields a large number of buggy programs whose mixed-typed versions are
suitable subjects for our experiment.  The mutation analysis of Lazarek et
al, is, however, completely useless for creating impedance mismatches.

While mutation analysis traditionally aims to inject bugs that challenge
extensive test suites, the ones yielding ill-typed mutants are usually deemed
\emph{incompetent}. As a matter of fact, mutation analysis frameworks are
fine-tuned to avoid them---yet it is precisely those that are needed for
evaluating blame assignment strategies. The mutators used here are newly designed,
inspired by the authors extensive experience with programming in Typed Racket.
They cause type errors that cover a wide range of Typed Racket's type system and moreover
reliably cause runtime exceptions in mixed-typed versions of mutants.

The second big challenge is the disparity of gradually
typed languages. While the approaches are well understood in theory,
they come with vastly different type systems, accommodate seemingly
incompatible language features, and apply to radically different coding
styles in the untyped world.  To eliminate the effect of these differences 
on its results, the application of an evaluation method to different
gradual typing systems must use the same test programs and the same type
system. Otherwise, results for different gradual typing systems 
do not share a common baseline and, therefore, do not lend support to any
conclusions about whether the value of blame changes from one system to
another. For instance, the case study presented here builds on
Greenman and Felleisen's transient variant for functional Typed
Racket~\cite{gf-icfp-2018} to obtain a transient semantics that is
comparable with Typed Racket's default natural one. The revised transient
variant accommodates many more linguistic features and library calls
in a way that is faithful to the transient
semantics~\cite{vss-popl-2017}.

Beyond the implementation issue, the method also faces the problem that
the three variants---the natural semantics, the transient semantics, and
the erasure semantics---come with three radically different blame
assignment strategies.  For example, the natural semantics assigns blame
to one component while transient assigns blame to a set of components. The
erasure semantics does not blame a component per se, but it comes with an
exception location and the usual stack traces. 

Supporting these strategies is {\em not\/} just an issue of language
implementation but affects greatly the behavior of the rational programmer.
Specifically, the rational programmer must come with \emph{modes}
that represent the alternative interpretations of blame. 
For instance, a programmer using transient may
pick the oldest element of a blame set as the next component to add types because
it corresponds to the earliest point in the program's evaluation that can
discover an impedance mismatch.  Another mode does not distinguish between the elements of the
blame set and has the rational programmer type all blamed components
at once. Because this second kind of step 
is more laborious than the first one, the analysis of the results must take 
into account the rational programmer's effort.

Besides the blame information they produce, the three gradual typing
systems also differ in the runtime type checks they perform. Therefore an
application of the evaluation method to a gradual typing system has to
factor in the effect of their different type checks to determine whether blame helps the
rational programmer find the cause of an impedance mismatch. A solution to this issue
is yet another mode for the rational programmer that uses information only
from the underlying languages exceptions to select the next component(s) to type.
This \emph{exception} mode simulates a rational programmer that ignores
blame and serves as the baseline for blame's value.


The final big challenge is that the different gradual type
systems, the number of necessary modes for the rational programmer
and the large number of mutants lead to an explosion of scenarios the
method needs to examine. Thus a practical application of the
method has no option but to carefully sample the space of scenarios while 
making sure that it still produces reproducible conclusions.


\smallskip

These challenges expose the subtlety of evaluating blame strategies but
also suggest a recipe:

%% for doing so correctly
%% MF: what is correct about this recipe? 

\begin{itemize}

\item Implement all three gradual type systems on a common
  basis (section~\ref{sec:landscape});

\item Generate a large set of programs with representative
  type errors that all three systems can detect (section~\ref{sec:mutate}); 
    
\item Simulate the rational programmer on these programs with sufficient 
  modes to (i) match the peculiarities of each  system and 
    (ii) isolate blame from other confounding factors
    (section~\ref{sec:rational});



\item Sample the experimental space  to obtain a computationally feasible
  but statistically meaningful experiment (section~\ref{sec:sample}).

\end{itemize}
