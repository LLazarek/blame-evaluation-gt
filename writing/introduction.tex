
Theoreticians of gradual typing have focused on blame theorems from the very
beginning~\cite{mf-toplas-2009, tf-dls-2006}. ``Well-typed
[components]\footnote{The original authors got this word wrong.} can't be
blamed'' turned the theorem into a slogan~\cite{wf-esop-2009}. Academic systems
(Reticulated Python~\cite{vsc-dls-2019, vss-popl-2017, vksb-dls-2014} and Typed
Racket~\cite{tf-dls-2006,tf-popl-2008,tfffgksst-snapl-2017,tf-icfp-2010}) come
with sophisticated blame assignment strategies. Their academic creators embrace
the idea that blame can help practicing programmers find impedance mismatches
between the types they added to a software system and the behavior of the
remaining untyped components.

Industrial implementors of gradual typing systems have almost
completely ignored blame assignment.  Systems such as Flow, Hack, or
TypeScript\footnote{See \url{https://flow.org},
\url{https://hacklang.org}, and \url{https://www.typescriptlang.org},
respectively.} exploit types for IDE actions and for finding typos in
code. Then their compilers remove types and rely on the built-in
safety checks of the underlying language to catch any problems.

This contrast between theory and applications of gradual typing raises the question 
\begin{quote}
 \it
 whether blame assignment adds any value to a gradually typed language,
 especially for the benefit of the working programmer.
\end{quote}
Given the long-standing academic interest in blame and its complete absence in
industrial systems, it comes as an even bigger surprise that the research
literature and the industrial blog world do not discuss any possible answers.
Instead, when language designers make relevant decisions, they seem to answer it
one way or another without any scientific justification. Then again, the
community has thus far failed to offer a method for evaluating blame assignment.

This paper's {\em first contribution\/} is {\em a method for evaluating the
effectiveness of blame assignment strategies\/} in the gradual typing world.
The top-level innovation is the idea of a {\em rational programmer\/}, that is,
a programmer that acts only in response to available information (see
sec.~\ref{sec:why-rational}). In the case of an impedance mismatch, the
available information consists of the error message and the current state of the
program. The rational programmer can hence use the former to change the
latter---and this systematic, information-driven process can be
implemented.\footnote{\citet{cc-snapl-19} use this tracing method to localize
type errors in inference-based gradual typing systems.}  Implementing it means
overcoming major challenges: injecting representative impedance mismatches;
putting the various kinds of error information to comparable use; and sampling
the huge space of possibilities (see sec.~\ref{sec:challenges}).

The paper's {\it second contribution\/} is a set of {\em results from applying
the evaluation method to three distinct blame assignment strategies and
approximately 72,200 cases\/} (see sec.~\ref{sec:results}): (1) {\it
Transient\/}, i.e. Reticulated's tracking of typed/untyped boundaries; (2) {\it
Natural\/}, i.e. the use of higher-order contract system and its blame
assignment~\cite{ff-icfp-2002}; and (3) {\it Erasure\/}, i.e. the approach of
industrial systems, which forgo blame in favor of error messages from the safety
checks of the underlying language.---The results (see
sec.~\ref{sec:discussion}) are at least somewhat surprising.  In principle
they validate the conjectures behind the work of theoreticians.  First, a good
blame assignment strategy helps with the search for impedance mismatches between
the specified types and the behavior of untyped components.  Second, Natural's
wrapper-based blame tracking is more useful than Transient's ``collective
blame'' tracking algorithm, which in turn is superior to Erasure. {\em But\/},
the application of the method also indicates problems with the expectations of
theoreticians. The first problem is that the cost of Transient's blame can be
huge. The second one concerns the difference between the methods; neither is
{\it Natural\/} vastly better than {\it Transient\/} nor are the two blame
assignment methods clearly preferable to {\it Erasure\/}.  In turn, these
problems suggests that, on one hand, the existing theory does not predict
practice properly, and on the other hand, the existing practice may need to find
additional ways to collect data.




